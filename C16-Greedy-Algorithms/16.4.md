### Exercises 16.4-1

------

Show that `( S, I[k] )` is a matroid, where `S` is any finite set and `I[k]` is the set of all subsets of `S` of size at most `k`, where `k <= |S|`.

### `Answer`

By definition of matroid:

1. **`S` is a finite set**
2. Assume that `k >= 0` then `I[k]` is nonempty. Let `B belongs to I[k]` , let `A is a subset of B`, we need to prove that `A belongs to I[k]` . Since `A is a subset of B` , then `|A| <= |B| ` . And `|B| <= k <= |S|` by problem definition. **Then `|A| <= k`, this means that `A belongs to I[k]`. **
3. Let `A, B belong to I[k]`, and `|A| < |B|`, we need to prove that there exists some element `x that belongs to B - A`, such that `A union { x } belongs to I[k]`.  Since `|A| < |B|`, then there are such element `x that is in B and not in A`, in other words `x is in B - A`. Since `|A| < |B| <= k` , size of `A` is at most `k - 1`. **Then we could add one element to `A` and resulting set will still be in `I[k]`, let this "one element" be `x`**

### Exercises 16.4-2

------

Given an `m * n` matrix `T ` over some field (such as the reals), show that `( S, I )` is a
matroid, where `S` is the set of columns of `T` and `A belongs to I` if and only if the columns
in `A` are linearly independent.

### `Answer`

1. **`( S = n ) ==> S is a finite set`**

2. Let `B = { c1, c2, ... , ck } belongs to I` (`B` is linearly independent) , let `A is a subset of B`, we need to prove that `A belongs to I` (`A` is linearly independent too).  

   By definition of independence: `{ c1, c2, ... , ck }` are said to be linearly independent, if there exist scalars `{ a1, a2, ... , ak }` not all zero, such that: `a1 * c1 + a2 * c2 + ... + ak * ck = 0`. 

   Let's made an assumption that `A` is linearly dependent, this means that there are some column `ci` that is a linear combination of other columns in `A`. But that means that `ci` is also a linear combination of columns in `B` which is linearly independent, contradiction. 

   **Then `A` is linearly independent too, which means that `A belongs to I`. ** 

3. Let `A, B belong to I`, and `|A| < |B|`, we need to prove that there exists some element `x that belongs to B - A`, such that `A union { x } belongs to I`.  If we couldnâ€™t add any column of `B` to `A` whilst preserving independence then it must be the case that every element of `B` is a linear combination of elements of `A`. But this implies that `A` spans a `|B|`-dimensional space, which is impossible.

   **Therefore we could add any column of `B` to `A`, with preserving independence.**

### Exercises 16.4-3

------

Show that if `( S, I )` is a matroid, then `( S, I')` is a matroid, where 

`I' = { A' : S - A' contains some maximal A, that belongs to I}`.

That is, the maximal independent sets  of `( S, I' )` are just the complements of the maximal  independent sets of `( S, I )`.

### `Answer`

1. **`S` is finite, because `( S, I )` is a matroid**

2. Let `B' belongs to I'` , let `A' is a subset of B'`, we need to prove that `A' belongs to I'`. 

   `B' belongs to I'`, therefore `S - B' contains some maximal B, that belongs to I`. **Then `S - A' which is a superset of S - B' contains some maximal B, that belongs to I ` too.**

3.  Let `A', B' belong to I'`, and `|A'| < |B'|`, we need to prove that there exists some element `y that belongs to B' - A'`, such that `A' union { y } belongs to I'`.

    `|A'| < |B'|  ==>	| S - B' | < | S - A' |`

   There are `maximal B belonging to I : B is a subset of S - B'`. We choose such set `C : |C| = |B| - 1 and C is a subset of maximal set of  S - A' ` ( note that `C` is independent as a subset of maximal set  ). Since `|C| < |B|`, by exchange property of matroid `( S, I )` there are such an element `x belongs to B - C`, that  `A = ( C union { x } ) belongs to I` ( note that `B` is maximal ). 

   **Let's choose `y : y != x and y belongs to B' - A' `.  Then `S - ( A' union { y } )` will still contain `C union { x }`. Which means that `A' is independent in I'`.**

### Exercises 16.4-4

------

Let S be a finite set and let `S[1], S[2], ... , S[k]` be a partition of `S` into nonempty disjoint
subsets. Define the structure `( S, I )` by the condition that 

`I = { A : | intersection of A and S[i] | <= 1 for i = 1, 2, ... , k }`.

Show that `( S, I )` is a matroid. That is, the set of all sets `A` that contain at most one member of each subset in the partition determines the independent sets of a matroid.

### `Answer`

1. **`S` is finite, since `k` is finite.**

2. Let `B belongs to I`, let `A is a subset of B`, we need to prove that `A belongs to I`.  

   **If `A is a subset of B`, then `|intersection of A and S[i]| <= 1 for i = 1, ... , k`**. This applies, since 

   `|A intersect S[i]| <= |B intersect S[i]| <= 1 for i = 1, 2, ... , k`	

3. Let `A, B belong to I`, and `|A| < |B|`, we need to prove that there exists some element `x that belongs to B - A`, such that `A union { x } belongs to I`. 

   Every set in `I` forms by deciding whether to include or not element from `S[i], i = 1, 2, ... , k`, if the decision is "yes", then we should choose what one element in `S[i]` we should select.

   `|A| < |B|` means that there are some sets, suppose just one -  `S[j]` , that one of its elements is in `B`, but not in `A`. **So we could add this element, to `A`, and because `|A intersect S[j]| <= 1`, it is still in `I`.**

   **Note**: if there are more than just one set, then we may select any.

### Exercises 16.4-5

------

Show how to transform the weight function of a weighted matroid problem, where the desired optimal solution is a minimum-weight maximal independent subset, to make it a standard weighted-matroid problem. Argue carefully that your transformation is correct.

### `Answer`

Suppose that `T` is the largest weight of any element. Let `w2(x) = T + 1 - w1(x)`, where `w1` is an initial weighted function. Let `S` be size of all maximal independent subsets. Let `S1` be a maximal independent subset with respect to `w2`, and `S2` is minimum-weight maximal independent subset with respect to `w1`. We need to prove that `w1(S1) = w1(S2)`. 

Suppose `w1(S1) > w1(S2)`. Then in terms of `w2`: `w2(S1) < w2(S2) `. But `S1` is a maximal independent subset with respect to `w2`, contradiction. **As a result `w1(S1) = w1(S2)`**

**Note**: `w1(S1) < w1(S2)` is impossible since `S2` is minimum-weight maximal independent subset with respect to `w1`.

------

Follow [@louis1992](https://github.com/gzc) on github to help finish this task.

